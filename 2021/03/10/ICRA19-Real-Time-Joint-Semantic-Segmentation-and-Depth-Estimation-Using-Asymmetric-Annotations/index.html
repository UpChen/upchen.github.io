<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|charter:300,300italic,400,400italic,700,700italic|Georgia:300,300italic,400,400italic,700,700italic|Cambria:300,300italic,400,400italic,700,700italic|"Times+New+Roman":300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"8.0.1","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content=".image {      border-radius: 0.3125em;     box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);      } .image_description {     display: inline-block;     color: #999;     font">
<meta property="og:type" content="article">
<meta property="og:title" content="[ICRA19] Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations">
<meta property="og:url" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/index.html">
<meta property="og:site_name" content="MINGCHEN&#39;s Blog">
<meta property="og:description" content=".image {      border-radius: 0.3125em;     box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);      } .image_description {     display: inline-block;     color: #999;     font">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/multi-task.jpg">
<meta property="og:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/multi_task_example.png">
<meta property="og:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/overview_network.png">
<meta property="og:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/label_mind_map.png">
<meta property="og:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/training_mind_map.png">
<meta property="og:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/results_test.png">
<meta property="og:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/Qualitative_results.png">
<meta property="og:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/ablation_study.png">
<meta property="article:published_time" content="2021-03-10T10:22:01.000Z">
<meta property="article:modified_time" content="2021-03-19T14:54:23.453Z">
<meta property="article:author" content="MINGCHEN">
<meta property="article:tag" content="Paper Analysis">
<meta property="article:tag" content="Multi-task Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/multi-task.jpg">


<link rel="canonical" href="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>[ICRA19] Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations | MINGCHEN's Blog</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">MINGCHEN's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Recording and sharing something.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#What-is-Multi-task-Learning"><span class="nav-number">1.</span> <span class="nav-text">What is Multi-task Learning</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Motivation"><span class="nav-number">2.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Contribution"><span class="nav-number">3.</span> <span class="nav-text">Contribution</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Propose-a-new-model-based-on-the-existing-model"><span class="nav-number">3.1.</span> <span class="nav-text">Propose a new model based on the existing model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Expert-Labeling-for-Asymmetric-Annotations"><span class="nav-number">3.2.</span> <span class="nav-text">Expert Labeling for Asymmetric Annotations</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Experiment"><span class="nav-number">4.</span> <span class="nav-text">Experiment</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#NYUDv2"><span class="nav-number">4.1.</span> <span class="nav-text">NYUDv2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ablation-Studies"><span class="nav-number">4.2.</span> <span class="nav-text">Ablation Studies</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Conclusion"><span class="nav-number">5.</span> <span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">6.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">MINGCHEN</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </section>
      </div>
        <div class="back-to-top animated">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/03/10/ICRA19-Real-Time-Joint-Semantic-Segmentation-and-Depth-Estimation-Using-Asymmetric-Annotations/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="MINGCHEN">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MINGCHEN's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [ICRA19] Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-03-10 10:22:01" itemprop="dateCreated datePublished" datetime="2021-03-10T10:22:01+00:00">2021-03-10</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-03-19 14:54:23" itemprop="dateModified" datetime="2021-03-19T14:54:23+00:00">2021-03-19</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Semantic-Segmentation/" itemprop="url" rel="index"><span itemprop="name">Semantic Segmentation</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <style type="text/css" rel="stylesheet">
.image { 
    border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08); 
    }
.image_description {
    display: inline-block;
    color: #999;
    font-size: 16px;
    padding: 2px
}
</style>

<p>This paper tries to solve the problem of deployment of deep leaning models on robotic as sensory information extractors [1]. They use multi-task learning to solve semantic segmentation and depth estimation problems at once. In addition, to get real-time performance, mobileNet and RefineNet are adopted.</p>
<a id="more"></a>

<h1 id="What-is-Multi-task-Learning"><a href="#What-is-Multi-task-Learning" class="headerlink" title="What is Multi-task Learning"></a>What is Multi-task Learning</h1><center>
    <img class="image" 
    style="width: 550px; height: 250px" 
    src="multi-task.jpg">
    <div class="image_description">Figure 1: [2].</div>
</center>
<br/>

<p>From the name, we can know multi-task learning means that try to make a single neural network to do several things at the same time [2]. Then hope that each task here can help all other tasks. </p>
<center>
    <img class="image" 
    style="width: 450px; height: 450x" 
    src="multi_task_example.png">
    <div class="image_description">Figure 2: An example of object detection [3].</div>
</center>
<br/>

<p>For example, object detection is using multi-task learning. You want to know if there are any people, cars, traffic lights or signs in the above image, if you are doing some researches about autonomous vehicles. This is a case of multi-task learning, cause you want to detect multiple objects from a single image.</p>
<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>The deployment of deep learning models in robotics as sensory information extractors:</p>
<ul>
<li>A single model to perform multiple tasks at once</li>
<li>Real-time</li>
<li>Using asymmetric datasets with uneven numbers of annotations</li>
</ul>
<h1 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h1><h2 id="Propose-a-new-model-based-on-the-existing-model"><a href="#Propose-a-new-model-based-on-the-existing-model" class="headerlink" title="Propose a new model based on the existing model"></a>Propose a new model based on the existing model</h2><center>
    <img class="image" 
    style="width: 1000px; height: 250px" 
    src="overview_network.png">
    <div class="image_description">Figure 3: General network structure for joint semantic segmentation and depth estimation. Each task has only 2 specific parametric layers, while everything is shared [1].</div>
</center>
<br/>

<p>To achieve real-time performance, they use Light-Weight RefineNet architecture built on top of the MobileNet-v2 classification network as the backbone network. MobileNet, proposed by the Google team, is a lightweight convolutional neural network. The main goal is to increase the accuracy of the existing algorithms while also increasing the speed in order to accelerate the application of deep networks on the mobile side. Then, RefineNet explicitly uses all the information of the downsampling process, and uses remote residual connections to achieve high-resolution predictions. Here i just introduce them briefly. We will focus on the usage of multi-task learning and asymmetric annotations.</p>
<p>The Chained Residual Pooling (CRP) block is to capture contextual features from large range resolution. Then, pooling layer can get useful features. The features wiil be fused according to weights that were learnt by convolution layers.</p>
<h2 id="Expert-Labeling-for-Asymmetric-Annotations"><a href="#Expert-Labeling-for-Asymmetric-Annotations" class="headerlink" title="Expert Labeling for Asymmetric Annotations"></a>Expert Labeling for Asymmetric Annotations</h2><center>
    <img class="image" 
    style="width: 800px; height: 180px" 
    src="label_mind_map.png">
    <div class="image_description">Figure 4: Expert labeling for asymmetric annotations.</div>
</center>
<br/>

<p>It is impossible to have all the ground truth sensory information available for each single image [1]. For this situation, a expert model maybe useful. Suppose the dataset is $ S $, then it is divided into two disjointed sets $ S_1 = S_{T_1} $ and $ S_2 = S_{T_1, T_2} $  such that $ S = S_1 \bigcup S_2 $, where $ T_1 $ and $ T_2 $ denote two tasks, respectively, and the set $ S_1 $ consists of images for which there are no annotations of the second task avaliable, while $ S_2 $ comprises images having both sets of annotations. Then, they rely on an expert model to provide the noisy estimation in place of missing annotations. </p>
<p>We will get the progress clearly in the next section.</p>
<h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><h2 id="NYUDv2"><a href="#NYUDv2" class="headerlink" title="NYUDv2"></a>NYUDv2</h2><p>NYUDv2 is an indoor dataset with 40 semantic labels. It contains 1449 RGB images with both segmentation and depth annotations, of which 795 is the training set and 654 is validation set [1]. In addition, they will use some (25000) of raw dataset with only depth annotations. Firstly, they annotate these raw images for semantic segmentation using a teacher network (pre-trained Light-weight RefineNet-152). After getting the synthetic annotations, they pre-train the network on the large set, then fine-tune it on the original small set of 795 images.</p>
<center>
    <img class="image" 
    style="width: 950px; height: 200px" 
    src="training_mind_map.png">
    <div class="image_description">Figure 5: The progress of processing the data and training.</div>
</center>
<br/>

<p>You may get a better understanding from this mind map. Next, are the results of their model.</p>
<center>
    <img class="image" 
    style="width: 850px; height: 250px" 
    src="results_test.png">
    <div class="image_description">Figure 6: Results on the test set of NYUDv2. The speed of a single forward pass and the number of FLOPs are measured on 640 x 480 inputs. For the reported mIoU the higher the better, whereas for the reported Root mean square error (RMSE) the lower the better [1].</div>
</center>
<br/>

<p>For the clarification, mIoU value is the higher the better and RMSE is the lower the better. From the figure 6, we can see the performance is good, although it is not the best.</p>
<center>
    <img class="image" 
    style="width: 600px; height: 300px" 
    src="Qualitative_results.png">
    <div class="image_description">Figure 7: Qualitative results on the test set of NYUD-v2. The black and dark-blue pixels in ‘GT-Segm’ and ‘GT-Depth’ respectively, indicate pixels without an annotation or label [1].</div>
</center>
<br/>

<p>These are the qualitative results. </p>
<h2 id="Ablation-Studies"><a href="#Ablation-Studies" class="headerlink" title="Ablation Studies"></a>Ablation Studies</h2><p>To evaluate the importance of pretraining using the synthetic annotations and benefits of performing two tasks jointly, they conduct a series of ablation experiments. </p>
<center>
    <img class="image" 
    style="width: 750px; height: 200px" 
    src="ablation_study.png">
    <div class="image_description">Figure 8: Results of ablation experiments on the test set of NYUDv2 [1]. Task update frequency denotes the number of examples of each task to be seen before performing a gradient step on task-specific parameters; base update frequency is the number of examples to be seen (regardless of the task) before performing a gradient step on shared parameters</div>
</center>
<br/>

<p>The first thing they did is comparing three baseline models trained on the small set of 795 images. However, the results show that performing two tasks jointly on the small set does not provide any significant benefits for each separate task, and even harms semantic segmentation. In contrast, having a large set of depth annotations results in valuable improvements in depth estimation and even semantic segmentation [1].</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>This paper propose a good way to solve the problem of labeling data. However, I think their demonstration of multi-task learning may not be convinced because of the small dataset which only has 795 images. If we have 20000 data with both segmentation and depth labels and 20000 raw data with only depth label, does multi-task leaning improve performance? </p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><p>Nekrasov, V., Dharmasiri, T., Spek, A., Drummond, T., Shen, C. and Reid, I., 2021. Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations. [online] arXiv.org. Available at: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.04766">https://arxiv.org/abs/1809.04766</a> [Accessed 10 March 2021].</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://bitesizebio.com/27766/multitasking-lab-not-multitasking/">https://bitesizebio.com/27766/multitasking-lab-not-multitasking/</a></p>
</li>
<li><p>Andrew Ng (2017), Deep Learning Course, Coursera.</p>
</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Paper-Analysis/" rel="tag"><i class="fa fa-tag"></i> Paper Analysis</a>
              <a href="/tags/Multi-task-Learning/" rel="tag"><i class="fa fa-tag"></i> Multi-task Learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/02/23/A-Brief-Survey-on-Mirror-Segmentation-with-Deep-Learning/" rel="prev" title="A Brief Survey on Mirror Segmentation with Deep Learning">
                  <i class="fa fa-chevron-left"></i> A Brief Survey on Mirror Segmentation with Deep Learning
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






      
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">MINGCHEN</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  


















  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css">

<script>
NexT.utils.loadComments('#gitalk-container', () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '799c5e58b7d6284f21ac',
      clientSecret: '4847a3a09afe4932a7029e2e12fa24ee902124fe',
      repo        : 'UpChen.github.io',
      owner       : 'UpChen',
      admin       : ['UpChen'],
      id          : 'b0c61e1da60a8b11a8a2d3b0e98575c8',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
