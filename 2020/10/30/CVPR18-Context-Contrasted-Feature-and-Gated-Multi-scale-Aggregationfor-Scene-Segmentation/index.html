<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|charter:300,300italic,400,400italic,700,700italic|Georgia:300,300italic,400,400italic,700,700italic|Cambria:300,300italic,400,400italic,700,700italic|"Times+New+Roman":300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"8.0.1","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content=".image {      border-radius: 0.3125em;     box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);      } .image_description {     display: inline-block;     color: #999;     font">
<meta property="og:type" content="article">
<meta property="og:title" content="[CVPR18] Context Contrasted Feature and Gated Multi scale Aggregationfor Scene Segmentation">
<meta property="og:url" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/index.html">
<meta property="og:site_name" content="MINGCHEN&#39;s Blog">
<meta property="og:description" content=".image {      border-radius: 0.3125em;     box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);      } .image_description {     display: inline-block;     color: #999;     font">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/overview.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/FCN.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/CCL.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/Visualization.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/Gated_sum.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/Validation_CCL.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/Validation_CCL_2.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/Validation_model.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/Pascal_Context.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/SUN-RGBD.png">
<meta property="og:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/COCO.png">
<meta property="article:published_time" content="2020-10-30T15:42:17.000Z">
<meta property="article:modified_time" content="2020-11-02T14:35:16.297Z">
<meta property="article:author" content="MINGCHEN">
<meta property="article:tag" content="Paper Analysis">
<meta property="article:tag" content="CCL">
<meta property="article:tag" content="gated sum">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/overview.png">


<link rel="canonical" href="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>[CVPR18] Context Contrasted Feature and Gated Multi scale Aggregationfor Scene Segmentation | MINGCHEN's Blog</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">MINGCHEN's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Just record and share my ideas</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Motivation"><span class="nav-number">2.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Contributions"><span class="nav-number">3.</span> <span class="nav-text">Contributions</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Context-Contrasted-Local-Feature"><span class="nav-number">3.1.</span> <span class="nav-text">Context Contrasted Local Feature</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Gated-Mult-scale-Aggregation"><span class="nav-number">3.2.</span> <span class="nav-text">Gated Mult-scale Aggregation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Experiments-amp-Conclusion"><span class="nav-number">4.</span> <span class="nav-text">Experiments &amp; Conclusion</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Validation-of-the-model"><span class="nav-number">4.1.</span> <span class="nav-text">Validation of the model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Results-On-Scene-Segmentation"><span class="nav-number">4.2.</span> <span class="nav-text">Results On Scene Segmentation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">MINGCHEN</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </section>
      </div>
        <div class="back-to-top animated">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="MINGCHEN">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MINGCHEN's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [CVPR18] Context Contrasted Feature and Gated Multi scale Aggregationfor Scene Segmentation
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-10-30 15:42:17" itemprop="dateCreated datePublished" datetime="2020-10-30T15:42:17+00:00">2020-10-30</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-11-02 14:35:16" itemprop="dateModified" datetime="2020-11-02T14:35:16+00:00">2020-11-02</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Semantic-Segmentation/" itemprop="url" rel="index"><span itemprop="name">Semantic Segmentation</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <style type="text/css" rel="stylesheet">
.image { 
    border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08); 
    }
.image_description {
    display: inline-block;
    color: #999;
    font-size: 16px;
    padding: 2px
}
</style>

<p><strong>Paper link :</strong> <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8578352">Context Contrasted Feature and Gated Multi-scale Aggregation for Scene Segmentation</a></p>
<p><strong>The link of Chinese version of this paper analysis :</strong></p>
<a id="more"></a>

<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>This paper provides two new ideas about the scene segmentation. One is <strong>context contrasted local feature (CCL)</strong>, another one is <strong>gated sum</strong>. In my opinon, CCL feature is extracted for each pixel to learn the details of local feature. It makes the model have strong performance for inconspicuous objects. Gated sum is a kind of weighted sum of different scale of features, which is a series of complicated operations in this paper even though it just makes little improvement of performance of the model. However, it is a good point that sum the features according to the importance.</p>
<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>This paper is to solved two problems on the scene segmentation. One is that the features extracted by deep convolutional neuro network (DCNN) are very abstract and </p>
<blockquote>
<p><strong>“inconspicous objects and stuff will be dominated by salient objects and its information will be somewhat weakened or even disregard, which is contradictory with the goal of scene segmentation [1].”</strong></p>
</blockquote>
<p>Here I just quote the sentence in this paper which is explained very well I think. Another problem is that the features of skip layers in previous work such as Fully Convolutional Network (FCN) are just simple summed and the different improtance of different scales are ignored.</p>
<h1 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h1><h2 id="Context-Contrasted-Local-Feature"><a href="#Context-Contrasted-Local-Feature" class="headerlink" title="Context Contrasted Local Feature"></a>Context Contrasted Local Feature</h2><p>Now, it’s time to introduce one of the leading roles CCL. In my opnion, you can understand the CCL model in one way that CCL model produce coarse context and delicate local feature for each pixel. Therefore, the DCNN model not only learn the abstract feature from images, but also learn the local feature for each pixel. Anyway, let’s into the paper and see what authors say.</p>
<center>
    <img class="image" 
    style="width: 450px; height: 450px" 
    src="overview.png">
    <div class="image_description">Figure 1: Overview of network framework [1].</div>
</center>
<br/>

<p>This is the overview of network framework. They use FCN-like architecture with ResNet-101 as backbone netwrok. We will compare this model with FCN and see what modifications are.</p>
<center>
    <img class="image" 
    style="width: 650px; height: 350px" 
    src="FCN.png">
    <div class="image_description">Figure 2: The architecture of FCN. Pooling and prediction layers are shown as grids that reveal relative spatial coarseness, while intermediate layers are shown as vertical lines [2].</div>
</center>
<br/>


<blockquote>
<p><strong>“CCL first contextualizes contrasted features at every block to obtain context aware local features, which combines two different scales in the feature level and take advantage of both context and local information [1]”</strong></p>
</blockquote>
<p>From the sentence I quoted and graph above, we can know that authors <strong>add more skip layers than in FCN and <font color="red">use CCL features at each block</font></strong>. The reason why add more skip layers is get richer scale feature maps. Ok, we already have a macro view about this model. Let’s into details of CCL features.</p>
<center>
    <img class="image" 
    style="width: 550px; height: 400px" 
    src="CCL.png">
    <div class="image_description">Figure 3: Context Contrasted Local (CCL). Each block of CCL consists of two parallel parts: coarse context and delicate local [1].</div>
</center>
<br/>

<center>
    <img class="image" 
    style="width: 500px; height: 300px" 
    src="Visualization.png">
    <div class="image_description">Figure 4: Visualization of different feature information [1].</div>
</center>
<br/>

<p>I think that watching two pictures above at the same time is easier to understand what CCL feature is doing. First, let’s look at the figure 3. Authors do normal and dilated convolutional operation on the same feature, then do minus operation each other. (Here I only explain the dilated convolution briely. Dilated convolution is that when you do dilated convolution you need to fill up zeros in the kernels or equal interval sampling features [3]). In this way, model could not only exploit useful context but also foreground the local information in contrast to the context.</p>
<blockquote>
<p><strong>“It is a mechanism that imitates human behavior. When our human beings look at one object we always collect discriminative-context for that object in a way that our eyes focus on that object in contrast to the blurred surroundings [1].”</strong></p>
</blockquote>
<p>It seems that this idea is inspired by the way of how people look at things. I haven’t read the book that this paper mentioned, but it makes sense I think. It is liked that we will only focus on the object cause the surrounding is blurred.</p>
<p>$$ CL=f_l(F,\Theta_l)-f_c(F,\Theta_c) \tag{1}$$</p>
<p>where $F$ is the input features, $f_l$ is the function of local $Conv$, $F_c$ is the function of context $Conv$, $\Theta_l$ and $\Theta_c$ are respective parameters, and $CL$ is the desired context contrasted local features. <font color="red">As for the question that my tutor mentioned why is not sum, I think the reason is that sum is not meet the blurred surrounding of theory. Since the result of sum is only sharp the local feature, the discriminal objects will still be dominated by salient objects and just a lesser degree. This is just my opinon, cause I didn’t try the code and test the differences of performance of the model between minus and sum operation.</font> On the other hand, my tutor said that six blocks maybe the result of tuning parameters during training process. That’s why authors said the number of blocks of Context-Local depends on your inputs.</p>
<h2 id="Gated-Mult-scale-Aggregation"><a href="#Gated-Mult-scale-Aggregation" class="headerlink" title="Gated Mult-scale Aggregation"></a>Gated Mult-scale Aggregation</h2><center>
    <img class="image" 
    style="width: 550px; height: 350px" 
    src="Gated_sum.png">
    <div class="image_description">Figure 5: Gated Sum could control the information flow of skip layers via its inherent gates [1].</div>
</center>
<br/>

<p>The idea of gated sum is easy to understand, but its details are little complicated. Let’s figure details out now. From the picture, we can know that the first step is info-skip layers consisting of $Conv+Sigmoid$ operations to generate information map. Then use the RNN to learn the relationship of these information maps which is important for the value of the Gate. <font color="red">In this step, I am still little confused about how and what RNN will lean. Next, the Global Refine just adds the global information and produce value of Gate. Final step, selectively aggreated score map through different value of Gate. </font> Below are math equations of Gated Sum.</p>
<p>$$I_p^n=f_i^n(F_p^n,\Theta_i^n) \tag{2}$$ </p>
<p>where $F_i^n$ is the function of $n$th info-skip layer $Conv+Sigmoid$ and $\Theta_i^n$ is its parameters. $I_p^n$ is an information map of size $H$ x $W$ x $1$ from corresponding feature. Then these information maps $I_p^n$ are inputted to RNN in sequence to learn their relationships:</p>
<p>$$h_p^n=tanh \left ( W^n \begin{pmatrix}<br>h_p^{n-1} \newline<br>I_p^n<br>\end{pmatrix} \right ) \tag{3}$$</p>
<p>where $h_p^n$ is the $n$ output of RNN. $W^n$ is its parameters.</p>
<p>$$ \overline{H_p}=f_g(H_p, \Theta_g)+H_p \tag{4}$$</p>
<p>where $f_g$ is a $1$ x $1$ $N$ x $N$ $Conv$ and $\Theta_g$ is its parameters. $H_p=(h_p^1 \cdots h_p^N)^T$ is the outputs of RNN are concatnated.</p>
<p>$$ G_p^n=N. \frac{e^{\overline{h_p^n}}} {\sum_{i=1}^N e^{\overline{h_p^i}}} \tag{5}$$</p>
<p><font color="red">why $e^{\overline{h_p^n}}$  Here I think that it’s possible to consider the calculation in some points like denominator can’t be zero.</font></p>
<p>the sum of $G_p^n$ for each position $p$ is normalized to $N$. Finally, $N$ score maps are selectively fused via gated sum:</p>
<p>$$ \overline{S_p^c}=\sum_{n=1}^N G_p^n S_p^{c,n} \tag{6}$$</p>
<p>where $\overline{S_p^c}$ is the output of gated sum.</p>
<h1 id="Experiments-amp-Conclusion"><a href="#Experiments-amp-Conclusion" class="headerlink" title="Experiments &amp; Conclusion"></a>Experiments &amp; Conclusion</h1><h2 id="Validation-of-the-model"><a href="#Validation-of-the-model" class="headerlink" title="Validation of the model"></a>Validation of the model</h2><p>In this section, I only want to focus the performance of the model on scene segmentation datasets rather than details of implements. Because I am not plan to reproduce this paper. Firstly, the baseline of this paper is FCN-like architecture with ResNet-101 (pre-trained on ImageNet). </p>
<center>
    <img class="image" 
    style="width: 450px; height: 200px" 
    src="Validation_CCL.png">
    <div class="image_description">Figure 6: Compare each other in terms of context aggregation (CA)[1].</div>
</center>
<br/>

<p>This experienment compares the performance of CCL with other current state of art models. It shows CCL is better than other models.</p>
<center>
    <img class="image" 
    style="width: 500px; height: 180px" 
    src="Validation_CCL_2.png">
    <div class="image_description">Figure 7: Ablation experiments of CCL on Pascal Context [1]. $LA$ abandons the context parts (dalited $Conv$) of CCL. $LA^d$ doubles the dimensionality of LA from 512 to 1024.</div>
</center>
<br/>

<p>Form the Figure 7, we can see that the CCL is actually worked. </p>
<center>
    <img class="image" 
    style="width: 450px; height: 250px" 
    src="Validation_model.png">
    <div class="image_description">Figure 8: Ablation experiments of Gated Sum on Pascal Context [1].</div>
</center>
<br/>

<p>We can know that the CCL makes a big improvement on the performance of model, but the gated sum seems to just have little help for the performance.</p>
<h2 id="Results-On-Scene-Segmentation"><a href="#Results-On-Scene-Segmentation" class="headerlink" title="Results On Scene Segmentation"></a>Results On Scene Segmentation</h2><center>
    <img class="image" 
    style="width: 450px; height: 500px" 
    src="Pascal_Context.png">
    <div class="image_description">Figure 9: Pascal Context testing accuracies [1].</div>
</center>
<br/>

<center>
    <img class="image" 
    style="width: 450px; height: 350px" 
    src="SUN-RGBD.png">
    <div class="image_description">Figure 10: SUN-RGBD (37 classes) segmentation results [1].</div>
</center>
<br/>

<center>
    <img class="image" 
    style="width: 450px; height: 200px" 
    src="COCO.png">
    <div class="image_description">Figure 11: Parsing performance of different networks on COCO Stuff dataset [1].</div>
</center>
<br/>

<p>That is why this paper can be published on CVPR. It is truly that has a good performance on scene segmentation. </p>
<hr>
<p><strong>If you have any questions, feel free to comment. Thanks for reading.</strong></p>
<p><font color="red"> 效果和ground truth 差不多</font></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li><p>Ding, H. et al. (2018) ‘Context Contrasted Feature and Gated Multi-scale Aggregation for Scene Segmentation’, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Computer Vision and Pattern Recognition (CVPR), pp. 2393–2402. doi: 10.1109/CVPR.2018.00254.</p>
</li>
<li><p>Shelhamer, E., Long, J. and Darrell, T. (2017) ‘Fully Convolutional Networks for Semantic Segmentation’, IEEE Transactions on Pattern Analysis and Machine Intelligence, Pattern Analysis and Machine Intelligence, IEEE Transactions on, IEEE Trans. Pattern Anal. Mach. Intell, 39(4), pp. 640–651. doi: 10.1109/TPAMI.2016.2572683.</p>
</li>
<li><p>点点点. (2019) ‘总结-空洞卷积(Dilated/Atrous Convolution)’, 知乎, <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/50369448">https://zhuanlan.zhihu.com/p/50369448</a>.  </p>
</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Paper-Analysis/" rel="tag"><i class="fa fa-tag"></i> Paper Analysis</a>
              <a href="/tags/CCL/" rel="tag"><i class="fa fa-tag"></i> CCL</a>
              <a href="/tags/gated-sum/" rel="tag"><i class="fa fa-tag"></i> gated sum</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/10/29/hello-world/" rel="prev" title="Hello World">
                  <i class="fa fa-chevron-left"></i> Hello World
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">MINGCHEN</span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  


















  








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
