<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|charter:300,300italic,400,400italic,700,700italic|Georgia:300,300italic,400,400italic,700,700italic|Cambria:300,300italic,400,400italic,700,700italic|"Times+New+Roman":300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"8.0.1","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content=".image {      border-radius: 0.3125em;     box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);      } .image_description {     display: inline-block;     color: #999;     font">
<meta property="og:type" content="article">
<meta property="og:title" content="Overview of Deep Learning Methods in Semantic Segmentation">
<meta property="og:url" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/index.html">
<meta property="og:site_name" content="MINGCHEN&#39;s Blog">
<meta property="og:description" content=".image {      border-radius: 0.3125em;     box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);      } .image_description {     display: inline-block;     color: #999;     font">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/Examples%20of%20semantic%20segmentation.jpeg">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/CNN%20and%20FCN.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/FCN_skip_connected.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/Visulization%20of%20Skip%20Connections.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/UNet.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/normal%20convolution.gif">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/dilated%20convolution.gif">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/Deeplab_v1.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/Dalited%20convolution%20compare.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/SPP.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/ASPP.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/Depthwise_Separable_Convolution.png">
<meta property="og:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/Deeplabv3.png">
<meta property="article:published_time" content="2020-12-09T11:09:43.000Z">
<meta property="article:modified_time" content="2020-12-28T18:23:23.517Z">
<meta property="article:author" content="MINGCHEN">
<meta property="article:tag" content="Overview">
<meta property="article:tag" content="FCN">
<meta property="article:tag" content="UNet">
<meta property="article:tag" content="Deeplab">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/Examples%20of%20semantic%20segmentation.jpeg">


<link rel="canonical" href="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Overview of Deep Learning Methods in Semantic Segmentation | MINGCHEN's Blog</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">MINGCHEN's Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Recording and sharing something.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#What-Is-Semantic-Segmentation"><span class="nav-number">1.</span> <span class="nav-text">What Is Semantic Segmentation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Fully-Convolutional-Neural-Network-FCN-2014-Nov"><span class="nav-number">2.</span> <span class="nav-text">Fully Convolutional Neural Network (FCN) 2014 Nov</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation"><span class="nav-number">2.1.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Contributions"><span class="nav-number">2.2.</span> <span class="nav-text">Contributions</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#UNet"><span class="nav-number">3.</span> <span class="nav-text">UNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Deeplab"><span class="nav-number">4.</span> <span class="nav-text">Deeplab</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Atrous-Convolution"><span class="nav-number">4.1.</span> <span class="nav-text">Atrous Convolution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deeplab-v2"><span class="nav-number">4.2.</span> <span class="nav-text">Deeplab v2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deeplab-v3-amp-v3"><span class="nav-number">4.3.</span> <span class="nav-text">Deeplab v3 &amp; v3++</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">MINGCHEN</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



        </section>
      </div>
        <div class="back-to-top animated">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/12/09/Overview-of-deep-learning-methods-in-Semantic-Segmentation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="MINGCHEN">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="MINGCHEN's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Overview of Deep Learning Methods in Semantic Segmentation
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-12-09 11:09:43" itemprop="dateCreated datePublished" datetime="2020-12-09T11:09:43+00:00">2020-12-09</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-12-28 18:23:23" itemprop="dateModified" datetime="2020-12-28T18:23:23+00:00">2020-12-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Semantic-Segmentation/" itemprop="url" rel="index"><span itemprop="name">Semantic Segmentation</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <style type="text/css" rel="stylesheet">
.image { 
    border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08); 
    }
.image_description {
    display: inline-block;
    color: #999;
    font-size: 16px;
    padding: 2px
}
</style>

<p>This article tries to make a summary of the development of deep learning methods in Semantic Segmentation, and talk about the motivation, concept and characteristic of these mehtods. So, this post just focus on the deep learning methods.</p>
<p><strong>The link of Chinese version of this post:</strong></p>
<a id="more"></a>

<h1 id="What-Is-Semantic-Segmentation"><a href="#What-Is-Semantic-Segmentation" class="headerlink" title="What Is Semantic Segmentation"></a>What Is Semantic Segmentation</h1><p>The first thing we need to know is that what is Semantic Segmentation. Semantic Segmentation is a kind of techniques to classify images in pixel level. Suppose you have a image with dogs, you need to classify every pixel of the image to cat or background. This is what Semantic Segmentation is doing [1]. Here I put examples of results of Semantic Segmentation to help you understand better.</p>
<center>
    <img class="image" 
    style="width: 550px; height: 400px" 
    src="Examples of semantic segmentation.jpeg">
    <div class="image_description">Figure 1: Results of Semantic Segmentation [1].</div>
</center>

<h1 id="Fully-Convolutional-Neural-Network-FCN-2014-Nov"><a href="#Fully-Convolutional-Neural-Network-FCN-2014-Nov" class="headerlink" title="Fully Convolutional Neural Network (FCN) 2014 Nov"></a>Fully Convolutional Neural Network (FCN) 2014 Nov</h1><p>One of the very early Deep Convolutional Neural Networks DCNN used for Semantic Segmentation is FCN network [2]. </p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>Some shortcomings for CNN to apply on Semantic Segmentation.</p>
<ul>
<li>Loss of Spatial Information</li>
<li>Computational Heavy</li>
<li>Fixed Inputs</li>
</ul>
<p>The emergence of a new technology must be because the existing technology cannot meet the demand. Therefore, there are some problems for triditional CNN-based methods to apply on Semantic Segmentation. First problem is loss of spatial information due to down-sampling operations (pooling or convolution). Semantic Segmentation requires the location information of each pixel so that there is a score map to match the original image. In addition,  fixed inputs and computational heavy are problems as well because of the fully connected layer. For fixed inputs, we need to cut the images to feed the model which is called Patch classification. The question is that the size of patch is difficult to define. Moreover, the size of patch make us only learn local features, which will limit the performance of model. For computational heavy, we all know that fully connected layer contain many parameters that need to be trained.</p>
<h2 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h2><p>To slove those problems that we talk about above, there are three contributions in the FCN networks, which also are differences from troditional CNN.</p>
<ul>
<li>None Fully Connected Layer</li>
<li>Deconvolution Layer</li>
<li>Skip Connections</li>
</ul>
<center>
    <img class="image" 
    style="width: 550px; height: 350px" 
    src="CNN and FCN.png">
    <div class="image_description">Figure 2: Transforming fully connected layers into convolution layers enables a classification net to output a heatmap [3].</div>
</center>
<br/>

<p>The neural network above in Figure 2 is a traditional neural network AlexNet. After the convolutional layer, several fully connected layers are connected, and finally a probability vector of the entire input image is obtained. On the contrary, FCN changes 4096-node, 4096-node and  1000-node fully connected layers to convolutional layers containing 4096, 4096 and 1000 1×1 convolution kernels. After this layer, a two-dimensional feature map is obtained. These solve the fixed inputs problem and give the model the ability of predicting arbitrary-sized inputs. Moreover, because fully connected layers are replaced by convolutional layer, the number of parameters is reduced which solve the computational heavy problem.</p>
<center>
    <img class="image" 
    style="width: 900px; height: 300px" 
    src="FCN_skip_connected.png">
    <div class="image_description">Figure 3: FCN network learns to combine coarse, high layer information with fine, low layer information [3].</div>
</center>
<br/>

<center>
    <img class="image" 
    style="width: 550px; height: 250px" 
    src="Visulization of Skip Connections.png">
    <div class="image_description">Figure 4: Refining fully convolutional nets by fusing information
from layers with deconvolutional operations [3].</div>
</center>
<br/>

<p>From figure 3 and 4, we can see that there are three heatmaps which are produced by up-sampling operations (deconvolution). This is to solve the loss of spatial information problem. Combining fine layers and coarse layers (by using skip connections) lets the model make local predictions that respect global structure [1].</p>
<p>FCN network is a landmark work for Semantic Segmentation, and a lot of subsequent work is based on it to improve. Although it has made a lot of contributions, there are still shortcomingsthe which are, the result of upsampling is still blurry and smooth, not sensitive to details in the image, and the spatial relationship of pixels is not considered. A variety of more advanced FCN-based approaches have been proposed to address these issues, including UNet, DeepLab [2].</p>
<h1 id="UNet"><a href="#UNet" class="headerlink" title="UNet"></a>UNet</h1><p>Differences between UNet and FCN</p>
<ul>
<li>Encoder-Decoder structure</li>
<li>Fusion of Features </li>
</ul>
<p>Encoder-Decoder model is now widely used in Computer Vision. The encoder is usually is a pre-trained classification network like VGG/ResNet followed by a decoder network. The task of the decoder is to semantically project the discriminative features (lower resolution) learnt by the encoder onto the pixel space (higher resolution) to get a dense classification [2]. </p>
<center>
    <img class="image" 
    style="width: 650px; height: 450px" 
    src="UNet.png">
    <div class="image_description">Figure 4: U-net Architecture [4].</div>
</center>
<br/>

<p>When you see the figure 4, may understand that why it is called UNet. It looks like a big U character. Compared with FCN network, UNet adopts the Encoder-Decoder structure and adds convolution operations after deconvolution. In this way, the high-resolution features from the encode part are combined with the up-sampled output. Then, successive convolutional layers can learn to assemble a more accurate output based on this information. </p>
<p>The second difference is the way of fusion of skip connected features and up-sampled features, FCN uses summation, and UNet uses concatenation. In my opinion, the dimension of the feature map has not changed if uses summation, but each dimension contains more features. For ordinary classification tasks, which do not need to be up-sampled from the feature map to the original resolution, it is an efficient choice; concatenation retains more dimension/location information, which allows the subsequent layers to freely choose between shallow and deep features, which is better for Semantic Segmentation tasks.</p>
<p>These are main differences in network structure. Next, we will look into another FCN-based work Deeplab.</p>
<h1 id="Deeplab"><a href="#Deeplab" class="headerlink" title="Deeplab"></a>Deeplab</h1><p>Before I introduce the deeplab, i will talk about the atrous convolution briefly.</p>
<h2 id="Atrous-Convolution"><a href="#Atrous-Convolution" class="headerlink" title="Atrous Convolution"></a>Atrous Convolution</h2><p>Dilated/Atrous convolution also calls convolution with holes [5]. It just inserts holes in the standard convolution map to increase reception field. Moreover, it has one more hyper-parameter dilated rate, which is the interval in the kernel (e.g. the dilated rate of normal convolution is 1).</p>
<center>
    <span style="float:left">
    <img class="image" 
    style="width: 350px; height: 300px" 
    src="normal convolution.gif">
    <div class="image_description">Figure 5: Standard convolution with a 3 x 3 kernel [6].</div>
    </span>
    <span>
    <img class="image" 
    style="width: 350px; height: 300px" 
    src="dilated convolution.gif">
    <div class="image_description">Figure 6: Dilated convolution with a 3 x 3 kernel and dilated rate 2 [6].</div>
    </span>
</center>
<br/>

<p>In Deep CNN, we always use down-sampling (pooling or convolution) to increase reception field and reduce the number of parameters. This will lead to the  loss of internal data structure and spatial hierarchical information which are important and useful for Semantic Segmentation. However, dilated convolution can increase reception field:  not only not lost the spatial information, but also increase the reception field. In addition, atrous convolution can combine the convolution and up-sample operations, which saves additional memory and time. </p>
<p>Next, we gonna look into the Deeplab.</p>
<p>Differences between Deeplab and FCN</p>
<ul>
<li>Atrous Convolution</li>
<li>Bi-linear Interpolation</li>
<li>Conditional Random Field (CRF)</li>
<li>Fusion of Features (same with UNet)</li>
</ul>
<center>
    <img class="image" 
    style="width: 650px; height: 350px" 
    src="Deeplab_v1.png">
    <div class="image_description">Figure 7: Model Illustration. The coarse score map from Deep Convolutional Neural Network (with fully convolutional layers) is upsampled by bi-linear interpolation. A fully connected CRF is applied to refine the segmentation result. Best viewed in color [7].</div>
</center>
<br/>

<p>Deeplab v1 do some improvements for Semantic Segmentation on FCN networks. First of all, they use dilated convolution to upsample the resulting map, which the advantage is shown on figure 8. We can know that the performance of dilated convolution is better. </p>
<center>
    <img class="image" 
    style="width: 550px; height: 330px" 
    src="Dalited convolution compare.png">
    <div class="image_description">Figure 8: Illustration of atrous convolution in 2-D. Top row: sparse feature extraction with standard convolution on a low resolution input feature map. Bottom row: Dense feature extraction with atrous convolution with rate r = 2, applied on a high resolution input feature map [8].</div>
</center>
<br/>

<p>Then, the score map will be up-sample by Bi-linear Interpolation which is different from FCN. Linear interpolation is to determine the rgb value of the target position based on the rgb values of the pixels on both sides, and the function used is a polynomial function. The Bi-linear interpolation means linear interpolation in both the horizontal and vertical directions. However, the effect on performance of different up-sample ways depends on the task. It doesn’t mean that Bi-linear Interpolation is better than deconvolution on all tasks. So, author uses this way maybe the result of training. After the interpolation operation, the result of up-sample will be addressed by CRF. CRF involves some knowledge of probability graphs. In my own words,  it will address the score map by calculating the spatial distance between the pixel and the surrounding pixels and the difference in RGB value, so that the result of the feature map is more refined. Fully connected means that when calculating the current pixel, it must be calculated with all pixels in the feature map except for it. The obvious disadvantage of this method is that the amount of calculation is large. And this method has not been adopted in later versions (v3&amp;v3++) of deeplab, so it will not be explained in detail here. </p>
<h2 id="Deeplab-v2"><a href="#Deeplab-v2" class="headerlink" title="Deeplab v2"></a>Deeplab v2</h2><p><strong>Atrous Spatial Pyramid</strong></p>
<p>To further improve the performance of the Deeplab v1 architecture, they use Atrous Spatial Pyramid to address the problem of existence of object at multuple scales [2].</p>
<center>
    <span style="float:left">
    <img class="image" 
    style="width: 460px; height: 300px" 
    src="SPP.png">
    <div class="image_description">Figure 9: Spatial Pyramid Pooling (SPP) [9].</div>
    </span>
    <span>
    <img class="image" 
    style="width: 460px; height: 300px" 
    src="ASPP.png">
    <div class="image_description">Figure 10: Atrous Spatial Pyramid Pooling (ASPP) [10].</div>
    </span>
</center>
<br/>

<p>This idea is inspired by Spatial Pyramid Pooling (SPP). The essence of SPP is a multi-layer maxpool, just in order to generate a fixed size $a$ x $a$ output for featur maps of different sizes $n$ x $n$, then the size of sliding window and the number of stride must be adaptive adjusted. Then multiple pooling with different fixed output sizes are combined to form an SPP. </p>
<p>ASPP is to apply multiple atrous convolution with different sampling rates to the input feature map, and fuse together. As objects of the same class can have different scales in the image, ASPP helps to account for different object scales which can improve the accuracy [2]. </p>
<h2 id="Deeplab-v3-amp-v3"><a href="#Deeplab-v3-amp-v3" class="headerlink" title="Deeplab v3 &amp; v3++"></a>Deeplab v3 &amp; v3++</h2><p>Here i will discuss v3 and v3++ as one model. </p>
<ul>
<li>Depthwise Separable Convolution</li>
<li>Encoder-Decoder Structure</li>
</ul>
<center>
    <img class="image" 
    style="width: 650px; height: 180px" 
    src="Depthwise_Separable_Convolution.png">
    <div class="image_description">Figure 11: Depthwise separable convolution for atrous convolution [10].</div>
</center>
<br/>

<p>Depthwise separable convolution is to increase computational efficiency. It decomposes a standard convolution into (a) a depthwise convolution (applying a single filter for each input channel) and (b) a pointwise convolution (combining the outputs from depthwise convolution across channels). For example, suppose you’ve an input RGB image of size $12$ x $12$ x $3$, the normal convolution operation using 256 filters of $5$ x $5$ x $3$  without padding and stride of 1 gives the output of size $8$ x $8$ x $256$. This whole operations costs $256$ x $5$ x $5$ x $3$ x $8$ x $8=1,228,800$ multiplications. If you use depthwise separable convolution, This whole operation took $3$ x $5$ x $5$ x $8$ x $8$ + $256$ x $1$ x $1$ x $3$ x $8$ x $8 = 53,952$ multiplication, which is far less compared to that of normal convolution [1]. Deeplab explores atrous separable convolution where atrous convolution is adopted in the depthwise convolution as well.</p>
<center>
    <img class="image" 
    style="width: 730px; height: 430px" 
    src="Deeplabv3.png">
    <div class="image_description">Figure 12: DeepLabv3+ extends DeepLabv3 by employing a encoder-decoder structure [10].</div>
</center>
<br/>

<p>From the figure 12, we can see changes about the decoder part which are to get a more refined result than DeepLabv3 especially along object boundaries. Specifically, after DeepLabV3+ samples 4x on the DeepLabv3 model output, then use $1$ x $1$ convolution reduces the dimensionality of DCNN’s output and concats it.<br>Finaly, result is up-sampling by Bilinear interpolation after using the $3$ x $3$ convolution.</p>
<p>Hope you have some understanding of the methods of semantic segmentation through this article, feel free to comment.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol>
<li>Kharshit Kumar. (2019) ‘Quick intro to semantic segmentation: FCN, U-Net and DeepLab’ Technical Fridays, <a target="_blank" rel="noopener" href="https://kharshit.github.io/blog/2019/08/09/quick-intro-to-semantic-segmentation">https://kharshit.github.io/blog/2019/08/09/quick-intro-to-semantic-segmentation</a>.  </li>
<li>Beeren Sahu. (2019) ‘The Evolution of Deeplab for Semantic Segmentation’ towards data science, <a target="_blank" rel="noopener" href="https://towardsdatascience.com/the-evolution-of-deeplab-for-semantic-segmentation-95082b025571">https://towardsdatascience.com/the-evolution-of-deeplab-for-semantic-segmentation-95082b025571</a>.</li>
<li>Shelhamer, E., Long, J. and Darrell, T. (2017) ‘Fully Convolutional Networks for Semantic Segmentation’, IEEE Transactions on Pattern Analysis and Machine Intelligence, Pattern Analysis and Machine Intelligence, IEEE Transactions on, IEEE Trans. Pattern Anal. Mach. Intell, 39(4), pp. 640–651. doi: 10.1109/TPAMI.2016.2572683.</li>
<li>Ronneberger, O., Fischer, P. and Brox, T., 2015. U-Net: Convolutional Networks For Biomedical Image Segmentation. [online] arXiv.org. Available at: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1505.04597">https://arxiv.org/abs/1505.04597</a> [Accessed 10 December 2020].</li>
<li>小草AI (2019), 腾讯云, <a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1467163">https://cloud.tencent.com/developer/article/1467163</a></li>
<li>vdumoulin, GitHub, <a target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic">https://github.com/vdumoulin/conv_arithmetic</a></li>
<li>Chen, L., Papandreou, G., Kokkinos, I., Murphy, K. and Yuille, A., 2016. Semantic Image Segmentation With Deep Convolutional Nets And Fully Connected Crfs. [online] arXiv.org. Available at: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1412.7062">https://arxiv.org/abs/1412.7062</a> [Accessed 15 December 2020].</li>
<li>L. Chen, G. Papandreou, I. Kokkinos, K. Murphy and A. L. Yuille, “DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs,” in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 40, no. 4, pp. 834-848, 1 April 2018, doi: 10.1109/TPAMI.2017.2699184.</li>
<li>He, K., Zhang, X., Ren, S. and Sun, J., 2020. Spatial Pyramid Pooling In Deep Convolutional Networks For Visual Recognition. arXiv.</li>
<li>Chen, L., Papandreou, G., Kokkinos, I., Murphy, K. and Yuille, A., 2020. Deeplab: Semantic Image Segmentation With Deep Convolutional Nets, Atrous Convolution, And Fully Connected Crfs. [online] arXiv.org. Available at: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.00915v2">https://arxiv.org/abs/1606.00915v2</a> [Accessed 26 December 2020].</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Overview/" rel="tag"><i class="fa fa-tag"></i> Overview</a>
              <a href="/tags/FCN/" rel="tag"><i class="fa fa-tag"></i> FCN</a>
              <a href="/tags/UNet/" rel="tag"><i class="fa fa-tag"></i> UNet</a>
              <a href="/tags/Deeplab/" rel="tag"><i class="fa fa-tag"></i> Deeplab</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/10/30/CVPR18-Context-Contrasted-Feature-and-Gated-Multi-scale-Aggregationfor-Scene-Segmentation/" rel="prev" title="[CVPR18] Context Contrasted Feature and Gated Multi Scale Aggregation for Scene Segmentation">
                  <i class="fa fa-chevron-left"></i> [CVPR18] Context Contrasted Feature and Gated Multi Scale Aggregation for Scene Segmentation
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






      
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">MINGCHEN</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  


















  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.css">

<script>
NexT.utils.loadComments('#gitalk-container', () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1.6.2/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '799c5e58b7d6284f21ac',
      clientSecret: '4847a3a09afe4932a7029e2e12fa24ee902124fe',
      repo        : 'UpChen.github.io',
      owner       : 'UpChen',
      admin       : ['UpChen'],
      id          : '8a1bb6d1df4d2d3cc76d6f20e2d4b10d',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
